{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_path': '<path to your chb-mit directory> e.g ./physionet.org/files/chbmit/1.0.0/', 'clean_data_path': '<path to store clean & aligned dataset> e.g ./data_clean', 'label_output_path': '<path to store generated TOML files> e.g ./ref_labels', 'ignore_lst': ['chb16_18.edf', 'chb16_19.edf', 'chb17c_13.edf', 'chb18_01.edf', 'chb19_01.edf', 'chb11_01.edf', 'chb12_27.edf', 'chb12_28.edf', 'chb12_29.edf', 'chb09_01.edf', 'chb15_01.edf']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"config.json\", \"rt\") as f:\n",
    "    config_obj = json.load(f)\n",
    "print(config_obj)\n",
    "globals().update(config_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Combined with command-line arguments\n",
    "with open(\"global_config.json\", \"rt\") as f:\n",
    "    config_obj = json.load(f)\n",
    "# globals().update(config_obj)\n",
    "dt_fmt = config_obj.datetime_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot.timeline import get_fig_from_obj\n",
    "from utils.iowrapper import EdfReaderWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Add TUH-EEG Extra Record Info\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.offline as pyo\n",
    "import pyedflib\n",
    "\n",
    "\n",
    "tuh_path = os.path.join(dataset_path, \"..\", \"..\", \"tuh_eeg\", \"v2.0.0\", \"edf\") # TODO 使用 latest 链接指代最新版本\n",
    "plot_args_path = timeline_info_path\n",
    "if \"plotly_fig_path\" not in globals(): # TODO 需要回顾一下名称查找规则\n",
    "    plotly_fig_path = \"timeline\"\n",
    "    os.makedirs(plotly_fig_path, exist_ok=True)\n",
    "# TODO Move plotly.min.js to plot_args_path\n",
    "\n",
    "def extract_values_from_pattern(pattern):\n",
    "    regex = r'(\\w+)_sz(\\d+)_edf(\\d+).json'\n",
    "    match = re.match(regex, pattern)\n",
    "    \n",
    "    if match:\n",
    "        pat = match.group(1)\n",
    "        sz_cnt = int(match.group(2))\n",
    "        edf_cnt = int(match.group(3))\n",
    "        \n",
    "        return sz_cnt, edf_cnt, pat\n",
    "    \n",
    "json_lst = list(os.scandir(plot_args_path))\n",
    "json_lst.sort(key=lambda fe: extract_values_from_pattern(fe.name)[:2], reverse=True)\n",
    "\n",
    "pat_2_complete_path = {extract_values_from_pattern(fe.name)[-1]: \"\" for fe in json_lst}\n",
    "for first_level_entry in os.scandir(tuh_path):\n",
    "    if first_level_entry.is_dir():\n",
    "        for second_level_entry in os.scandir(first_level_entry):\n",
    "            if second_level_entry.is_dir() and second_level_entry.name in pat_2_complete_path:\n",
    "                pat_2_complete_path[second_level_entry.name] = second_level_entry.path\n",
    "\n",
    "for fe in json_lst:\n",
    "    with open(fe.path, \"rt\") as f:\n",
    "        info_obj = json.load(f)\n",
    "    pat_record_lst = info_obj[\"record_lst\"]\n",
    "    pat_seizure_lst = info_obj[\"seizure_lst\"]\n",
    "\n",
    "    fig = get_fig_from_obj(title=fe.name, info_obj=info_obj)\n",
    "\n",
    "    record_fn_lst =  glob.glob(os.path.join(pat_2_complete_path[extract_values_from_pattern(fe.name)[-1]], \"**\", \"*.edf\"), recursive=True)\n",
    "    pat_complete_lst = []\n",
    "\n",
    "    for edf_path in record_fn_lst:\n",
    "        with EdfReaderWrapper(edf_path) as pedf:\n",
    "            start_dt = pedf.getStartdatetime()\n",
    "            end_dt = start_dt + timedelta(seconds=(edf_len := pedf.getFileDuration()))\n",
    "            fs = pedf.getSampleFrequency(0)\n",
    "            # assert all((FS := pedf.getSampleFrequencies()) == fs) # TODO 支持过滤非脑电数据通道\n",
    "            pat_complete_lst.append({\n",
    "                \"file\": os.path.basename(edf_path), \n",
    "                # \"span\": [start_dt.strftime(dt_fmt), end_dt.strftime(dt_fmt)], \n",
    "                \"span\": [start_dt, end_dt], \n",
    "                \"info\": f\"{os.path.basename(edf_path)} of shape {pedf.signals_in_file, pedf.getNSamples()[0]}\"\n",
    "            })\n",
    "\n",
    "    base = [seg[\"span\"][0] for seg in pat_complete_lst]\n",
    "    length = [(seg[\"span\"][1] - seg[\"span\"][0]).total_seconds() * 1000 for seg in pat_complete_lst]\n",
    "    text = [seg[\"info\"] for seg in pat_complete_lst]\n",
    "    color = \"LightSeaGreen\"\n",
    "\n",
    "    offset=-8; width=4# ; ymin=offset+width\n",
    "    fig.add_bar(\n",
    "        base=base,\n",
    "        x=length, \n",
    "        y=[0] * len(pat_complete_lst),\n",
    "        hovertext=text, \n",
    "        orientation='h', \n",
    "        marker=dict(\n",
    "            color=color,\n",
    "            # opacity=opacity, \n",
    "        ), \n",
    "        name=\"Origin\", \n",
    "        offset=offset, \n",
    "        width=[width] * len(pat_complete_lst), \n",
    "    )     \n",
    "        \n",
    "    # print(f\"Prepare to plot {fe.name}\")\n",
    "    if len(pat_record_lst) != len(pat_complete_lst): print(f\"{fe.name[:-4]} non equal!\")\n",
    "    pyo.plot(fig, filename=os.path.join(plotly_fig_path, fe.name[5:-4]+\".html\"), # include_plotlyjs=\"./plotly.min.js\", \n",
    "                auto_open=False, image='svg', image_width=2560, image_height=1440)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
