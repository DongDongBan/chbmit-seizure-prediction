{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyedflib import EdfReader\n",
    "\n",
    "class EdfReaderWrapper(EdfReader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        super().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tuh_sz_path = os.path.join(dataset_path, \"edf\")\n",
    "plot_args_path = timeline_info_path; os.makedirs(plot_args_path, exist_ok=True)\n",
    "\n",
    "import os\n",
    "import json, csv\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import pyedflib\n",
    "import pandas as pd\n",
    "\n",
    "with os.scandir(tuh_sz_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            # subdir_path = entry.path\n",
    "            with os.scandir(entry.path) as pats:\n",
    "                for pat in pats:\n",
    "                    if pat.is_dir():\n",
    "                        result_obj = {\"record_lst\": [], \"seizure_lst\": [], \"unused_rec_idx_lst\": []}\n",
    "                        record_fn_lst =  glob.glob(os.path.join(pat.path, \"**\", \"*.edf\"), recursive=True)\n",
    "                        \n",
    "                        for edf_path in record_fn_lst:\n",
    "                            with EdfReaderWrapper(edf_path) as pedf: \n",
    "                                start_dt = pedf.getStartdatetime()\n",
    "                                end_dt = start_dt + timedelta(seconds=(edf_len := pedf.getFileDuration()))\n",
    "                                fs = pedf.getSampleFrequency(0)\n",
    "                                # assert all((FS := pedf.getSampleFrequencies()) == fs) # TODO 支持过滤非脑电数据通道\n",
    "                                result_obj[\"record_lst\"].append({\n",
    "                                    \"file\": os.path.basename(edf_path), \n",
    "                                    # \"span\": [start_dt.strftime(dt_fmt), end_dt.strftime(dt_fmt)], \n",
    "                                    \"span\": [start_dt, end_dt], \n",
    "                                    \"info\": f\"{os.path.basename(edf_path)} records {start_dt} ~ {end_dt} \\r\\n of shape {pedf.signals_in_file, pedf.getNSamples()[0]}\"\n",
    "                                })\n",
    "                            \n",
    "                            with open(edf_path[:-3]+\"csv_bi\", \"rt\") as fcsv:\n",
    "                                rows = (row for row in fcsv if not row.startswith('#') and row.strip() != '')\n",
    "                                reader = csv.DictReader(rows)\n",
    "                                for row in reader:\n",
    "                                    if row[\"label\"] == \"bckg\":\n",
    "                                        continue\n",
    "                                    # TODO Assertion Needed Here\n",
    "                                    # assert row[\"label\"] == \"seiz\"\n",
    "                                    # assert row[\"channel\"] == \"TERM\"\n",
    "                                    # assert 0 <= float(row[\"start_time\"]) < float(row[\"stop_time\"]) <= edf_len\n",
    "                                    result_obj[\"seizure_lst\"].append({\n",
    "                                        \"span\": [start_dt+timedelta(seconds=float(row[\"start_time\"])), start_dt+timedelta(seconds=float(row[\"stop_time\"]))], \n",
    "                                        \"info\": f'Onset {start_dt+timedelta(seconds=float(row[\"start_time\"]))}, last {float(row[\"stop_time\"]) - float(row[\"start_time\"])}s'\n",
    "                                    })\n",
    "                            # TODO Add more verification\n",
    "                        result_obj[\"record_lst\"].sort(key=lambda obj:obj[\"span\"])\n",
    "                        result_obj[\"seizure_lst\"].sort(key=lambda obj:obj[\"span\"])\n",
    "                        for k, rec_info in enumerate(result_obj[\"record_lst\"]):\n",
    "                            if rec_info[\"file\"] in ignore_lst:\n",
    "                                result_obj[\"unused_rec_idx_lst\"].append(k)\n",
    "                            rec_info[\"span\"] = [rec_info[\"span\"][0].strftime(dt_fmt), rec_info[\"span\"][1].strftime(dt_fmt)]\n",
    "                        \n",
    "                        for seiz_info in result_obj[\"seizure_lst\"]:\n",
    "                            seiz_info[\"span\"] = [seiz_info[\"span\"][0].strftime(dt_fmt), seiz_info[\"span\"][1].strftime(dt_fmt)]\n",
    "                            \n",
    "                        with open(os.path.join(plot_args_path, f'{pat.name}_sz{len(result_obj[\"seizure_lst\"])}_edf{len(result_obj[\"record_lst\"])}.json'), \"wt\") as fout:\n",
    "                            json.dump(result_obj, fout, indent=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
