{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_path': '<path to your chb-mit directory> e.g ', 'clean_data_path': '<path to store clean & aligned dataset> e.g ./data_clean', 'label_output_path': '<path to store generated TOML files> e.g ./ref_labels', 'ignore_lst': []}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"config.json\", \"rt\") as f:\n",
    "    config_obj = json.load(f)\n",
    "print(config_obj)\n",
    "globals().update(config_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# clean_data_path = \"./swecethz-clean/\"\n",
    "plot_args_path = timeline_info_path; os.makedirs(plot_args_path, exist_ok=True)\n",
    "# TODO Combined with command-line arguments\n",
    "with open(os.path.join(\"..\", \"global_config.json\"), \"rt\") as f:\n",
    "    config_obj = json.load(f)\n",
    "# globals().update(config_obj)\n",
    "dt_fmt = config_obj.datetime_fmt\n",
    "\n",
    "fake_start_dt = datetime.strptime(fake_start_datetime, dt_fmt)\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "with os.scandir(clean_data_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            # subdir_path = entry.path\n",
    "\n",
    "            result_obj = {\"record_lst\": [], \"seizure_lst\": [], \"unused_rec_idx_lst\": []}\n",
    "            with open(os.path.join(entry.path, entry.name+\"_info.json\"), \"rt\") as finfo:\n",
    "                info = json.load(finfo)\n",
    "                for sbeg, send in zip(info[\"seizure_begin\"], info[\"seizure_end\"]):\n",
    "                    result_obj[\"seizure_lst\"].append({\n",
    "                        \"span\": [(fake_start_dt+timedelta(seconds=sbeg)).strftime(dt_fmt), \n",
    "                                 (fake_start_dt+timedelta(seconds=send)).strftime(dt_fmt)], \n",
    "                        \"info\": f\"Onset {fake_start_dt+timedelta(seconds=sbeg)}, last {send-sbeg}s\"\n",
    "                    })\n",
    "                fs = info[\"fs\"]\n",
    "            with open(os.path.join(entry.path, entry.name+\"_data.json\"), \"rt\") as fdata:\n",
    "                matsinfo = json.load(fdata)\n",
    "                cur_dt = fake_start_dt\n",
    "                for k, mat in enumerate(matsinfo):\n",
    "                    new_dt = cur_dt+timedelta(seconds=(mat[1][\"__shape__\"][1]/fs))\n",
    "                    result_obj[\"record_lst\"].append({\n",
    "                        \"file\": mat[0], \n",
    "                        \"span\": [cur_dt.strftime(dt_fmt), \n",
    "                                 new_dt.strftime(dt_fmt)], \n",
    "                        \"info\": f\"{mat[0]} records {cur_dt} ~ {new_dt} \\r\\n of shape {mat[1]['__shape__']} \"\n",
    "                                    f\"{cur_dt} ~ {new_dt}\"\n",
    "                    })\n",
    "                    if mat[0] in ignore_lst:\n",
    "                        result_obj[\"unused_rec_idx_lst\"].append(k)\n",
    "                    cur_dt = new_dt\n",
    "\n",
    "            with open(os.path.join(plot_args_path, entry.name+\".json\"), \"wt\") as f:\n",
    "                json.dump(result_obj, f, indent=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
