{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data_clean\"\n",
    "patient_lst = None  # Use subset of all 24 patients\n",
    "fs = 256 # Sampling Rate: 256Hz\n",
    "# ------------------------------------------------------------------------------\n",
    "# Prediction-specific Parameters\n",
    "# ------------------------------------------------------------------------------\n",
    "seizure_occurance_period = 30  # Seizure occurrence period (minutes)\n",
    "seizure_prediction_horizon = 5  # Seizure prediction horizon (minutes)\n",
    "# seizure_affected_area = 120 # (minutes) This parameter was split into the following 2 params\n",
    "seizure_affected_before = 60 # (minutes)\n",
    "seizure_affected_after = 60 # (minutes)\n",
    "# ------------------------------------------------------------------------------\n",
    "extract_ictal_samples = True\n",
    "extract_preictal_samples = True\n",
    "extract_interictal_samples = True\n",
    "# OUTPUT JSON PATH -------------------------------------------------------------\n",
    "output_dir = \"segment_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "from warnings import warn\n",
    "if seizure_affected_before < (seizure_occurance_period + seizure_prediction_horizon):\n",
    "    warn(f'Parameter seizure_affected_before shall be greater-equal than seizure_occurance_period + seizure_prediction_horizon!\\n \\\n",
    "           Replace {seizure_affected_before} with {seizure_occurance_period + seizure_prediction_horizon}')\n",
    "    seizure_affected_before = (seizure_occurance_period + seizure_prediction_horizon)\n",
    "\n",
    "subdir = os.path.join(output_dir, '%d-%d-%d-%d' % (seizure_occurance_period, # Output dir name by SOP-SPH-SAB-SAA\n",
    "                                                  seizure_prediction_horizon, \n",
    "                                                  seizure_affected_before, \n",
    "                                                  seizure_affected_after ))\n",
    "\n",
    "dt_fmt = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "# Store preictal and non-interictal in a dict\n",
    "pre_noninter_dict = {}\n",
    "for pat_id in (patient_lst if patient_lst else range(1, 24+1)):        \n",
    "    record_info = []; onset_info = []; pre_info = []; noninter_info = []\n",
    "\n",
    "    pat_pre_segs = []; pat_onset_segs = []; pat_inter_segs = []\n",
    "    with open(os.path.join(data_dir, 'chb%02d' % pat_id, 'datetime_info.json'), 'r') as f:\n",
    "        record_lst = json.load(f)\n",
    "        for record in record_lst:\n",
    "            edf_name = record['File Name']\n",
    "            start_str, end_str = record['Record Datetimes']\n",
    "            start_dt, end_dt = datetime.datetime.strptime(start_str, dt_fmt), datetime.datetime.strptime(end_str, dt_fmt)\n",
    "            record_info.append((start_dt, end_dt, edf_name))\n",
    "            for nsz, sz_span in enumerate(record['Seizures']):\n",
    "                sz_start_sec, sz_end_sec = sz_span\n",
    "                sz_start_dt, sz_end_dt = start_dt + datetime.timedelta(seconds=sz_start_sec), start_dt + datetime.timedelta(seconds=sz_end_sec)\n",
    "                if extract_preictal_samples:\n",
    "                    preStartTime = sz_start_dt - datetime.timedelta(minutes=seizure_occurance_period+seizure_prediction_horizon)\n",
    "                    preEndTime = sz_start_dt - datetime.timedelta(minutes=seizure_prediction_horizon)\n",
    "                    postictal_end_dt = onset_info[-1][1] + datetime.timedelta(minutes=seizure_affected_after) if len(onset_info) else datetime.datetime.min # 不能将前一个发作的发作后期也算进当前发作的前期\n",
    "                    preStartTime = max(preStartTime, postictal_end_dt)\n",
    "                    if preStartTime < preEndTime:                    \n",
    "                        # The preictal section falls completely in the current file\n",
    "                        if preStartTime >= start_dt:\n",
    "                            pat_pre_segs.append({'Label': 'Pre%d' % (len(onset_info)+1), \n",
    "                                                'File': edf_name[:-3] + 'npy', \n",
    "                                                'Span': [(preStartTime - start_dt).total_seconds(), (preEndTime - start_dt).total_seconds()]})\n",
    "                            \n",
    "                        else:\n",
    "                            subsegcnt = 0\n",
    "                            # Backward iteration search for preictal segments in previous records\n",
    "                            for k in range(len(record_info)-1, -1, -1):\n",
    "                                if (record_info[k][1] < preStartTime):\n",
    "                                    break\n",
    "                                if (record_info[k][0] > preEndTime):\n",
    "                                    continue\n",
    "                                sectStart = preStartTime if preStartTime >= record_info[k][0] else record_info[k][0]\n",
    "                                sectEnd = preEndTime if preEndTime <= record_info[k][1] else record_info[k][1]\n",
    "                                subsegcnt += 1\n",
    "                                pat_pre_segs.append({'Label': 'Pre%d-' % (len(onset_info)+1), \n",
    "                                                    'File': record_info[k][2][:-3] + 'npy', \n",
    "                                                    'Span': [(sectStart - record_info[k][0]).total_seconds(), (sectEnd - record_info[k][0]).total_seconds()]})                                \n",
    "                            for m in range(subsegcnt):\n",
    "                                pat_pre_segs[m-subsegcnt]['Label'] = pat_pre_segs[m-subsegcnt]['Label'] + str(m+1) \n",
    "                            \n",
    "                                \n",
    "\n",
    "                onset_info.append((edf_name, sz_start_dt, sz_end_dt))    \n",
    "                noninter_info.append((sz_start_dt - datetime.timedelta(minutes=seizure_affected_before), \n",
    "                                     sz_end_dt + datetime.timedelta(minutes=seizure_affected_after)))  \n",
    "                if extract_ictal_samples:\n",
    "                    pat_onset_segs.append({'Label': 'Onset%d' % len(onset_info), \n",
    "                                            'File': edf_name[:-3] + 'npy', \n",
    "                                            'Span': [sz_start_sec, sz_end_sec]})                      \n",
    "    \n",
    "    if extract_interictal_samples:\n",
    "        inter_affiliated_onset_cnt = [0] * (len(noninter_info)+1)\n",
    "        inter_noaffiliated_onset_cnt = 0\n",
    "        fake_sz_start_dt = record_info[-1][1] # Pretending to have a neighboring onset not recorded after the last file's last recording moment\n",
    "        fake_sz_inter_end_dt = fake_sz_start_dt - datetime.timedelta(minutes=seizure_affected_before)        \n",
    "        for dt0, dt1, fn in record_info: # See noninter_info inner structures above\n",
    "            queue = [(dt0, dt1)] # the list of periods that can be considered as interictal in fn\n",
    "            already_checked_period_lst = [] # Store the results of BFS\n",
    "            for nsz, non_dts in enumerate(noninter_info):\n",
    "                nt0, nt1 = non_dts\n",
    "                if (nsegs := len(queue)) == 0:\n",
    "                    break\n",
    "                for _ in range(nsegs):\n",
    "                    t0, t1 = queue.pop()\n",
    "                    if nt0 >= t1:\n",
    "                        already_checked_period_lst.append((nsz+1, t0, t1))\n",
    "                    elif nt1 <= t0:\n",
    "                        queue.append((t0, t1))\n",
    "                    else:\n",
    "                        if nt0 > t0:\n",
    "                            already_checked_period_lst.append((nsz+1, t0, nt0))\n",
    "                        if nt1 < t1:\n",
    "                            queue.append((nt1, t1))\n",
    "            \n",
    "            for k, t0, t1 in already_checked_period_lst:\n",
    "                inter_affiliated_onset_cnt[k] += 1\n",
    "                start_s = (t0 - dt0).total_seconds()\n",
    "                end_s = (t1 - dt0).total_seconds()\n",
    "\n",
    "                pat_inter_segs.append({'Label': 'Inter%d-%d' % (k, inter_affiliated_onset_cnt[k]), \n",
    "                                    'File': fn[:-3] + 'npy', \n",
    "                                    'Span': [start_s, end_s]})\n",
    "            \n",
    "            for t0, t1 in queue:\n",
    "                if t0 >= fake_sz_inter_end_dt:\n",
    "                    break\n",
    "                t1 = min(t1, fake_sz_inter_end_dt)                \n",
    "                inter_noaffiliated_onset_cnt += 1\n",
    "                start_s = (t0 - dt0).total_seconds()\n",
    "                end_s = (t1 - dt0).total_seconds()\n",
    "    \n",
    "                pat_inter_segs.append({'Label': 'Inter+-%d' % (inter_noaffiliated_onset_cnt), \n",
    "                                    'File': fn[:-3] + 'npy', \n",
    "                                    'Span': [start_s, end_s]})     \n",
    "\n",
    "    # Merge Results and output json files\n",
    "    pat_dir = os.path.join(subdir, 'chb%02d' % pat_id)\n",
    "    os.makedirs(pat_dir, mode=0o755, exist_ok=True)\n",
    "\n",
    "    pat_all_segs = [*pat_onset_segs, *pat_pre_segs, *pat_inter_segs]\n",
    "    pat_edf2idx = {t[2]: n for n, t in enumerate(record_info)} # Auxiliary sort usage\n",
    "    pat_all_segs.sort(key=lambda x: (pat_edf2idx[x['File']], x['Span']))\n",
    "    pat_all_segs = [{k: (v if k != 'Span' else [round(i*fs) for i in v]) for k, v in d.items()} for d in pat_all_segs] # get idx by multiply Span in seconds with fs written by Bing\n",
    "\n",
    "    with open(os.path.join(pat_dir, 'segment_info.json'), 'w') as fout:\n",
    "        json.dump(pat_all_segs, fout, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Label': 'Pre1-1', 'File': 'chb24_01.npy', 'Span': [0, 46080]},\n",
       " {'Label': 'Onset1', 'File': 'chb24_01.npy', 'Span': [122880, 129280]},\n",
       " {'Label': 'Onset2', 'File': 'chb24_01.npy', 'Span': [627456, 633856]},\n",
       " {'Label': 'Pre3-1', 'File': 'chb24_02.npy', 'Span': [626688, 905984]},\n",
       " {'Label': 'Onset3', 'File': 'chb24_03.npy', 'Span': [59136, 66560]},\n",
       " {'Label': 'Onset4', 'File': 'chb24_03.npy', 'Span': [738048, 744448]},\n",
       " {'Label': 'Onset5', 'File': 'chb24_04.npy', 'Span': [278528, 286720]},\n",
       " {'Label': 'Onset6', 'File': 'chb24_04.npy', 'Span': [361216, 368128]},\n",
       " {'Label': 'Onset7', 'File': 'chb24_04.npy', 'Span': [446720, 451584]},\n",
       " {'Label': 'Pre8-2', 'File': 'chb24_05.npy', 'Span': [700416, 921600]},\n",
       " {'Label': 'Pre8-1', 'File': 'chb24_06.npy', 'Span': [0, 237824]},\n",
       " {'Label': 'Onset8', 'File': 'chb24_06.npy', 'Span': [314624, 320768]},\n",
       " {'Label': 'Onset9', 'File': 'chb24_07.npy', 'Span': [9728, 15360]},\n",
       " {'Label': 'Inter10-1', 'File': 'chb24_08.npy', 'Span': [7936, 448512]},\n",
       " {'Label': 'Pre10-2', 'File': 'chb24_08.npy', 'Span': [832512, 921600]},\n",
       " {'Label': 'Pre10-1', 'File': 'chb24_09.npy', 'Span': [0, 369920]},\n",
       " {'Label': 'Onset10', 'File': 'chb24_09.npy', 'Span': [446720, 451584]},\n",
       " {'Label': 'Inter11-1', 'File': 'chb24_10.npy', 'Span': [444928, 904704]},\n",
       " {'Label': 'Pre11', 'File': 'chb24_11.npy', 'Span': [365312, 826112]},\n",
       " {'Label': 'Onset11', 'File': 'chb24_11.npy', 'Span': [902912, 920832]},\n",
       " {'Label': 'Pre12', 'File': 'chb24_13.npy', 'Span': [304128, 764928]},\n",
       " {'Label': 'Onset12', 'File': 'chb24_13.npy', 'Span': [841728, 845824]},\n",
       " {'Label': 'Onset13', 'File': 'chb24_14.npy', 'Span': [496384, 503296]},\n",
       " {'Label': 'Pre14', 'File': 'chb24_15.npy', 'Span': [494336, 832512]},\n",
       " {'Label': 'Onset14', 'File': 'chb24_15.npy', 'Span': [909312, 913664]},\n",
       " {'Label': 'Pre15', 'File': 'chb24_17.npy', 'Span': [362240, 823040]},\n",
       " {'Label': 'Onset15', 'File': 'chb24_17.npy', 'Span': [899840, 916736]},\n",
       " {'Label': 'Inter16-1', 'File': 'chb24_18.npy', 'Span': [898048, 921600]},\n",
       " {'Label': 'Inter16-2', 'File': 'chb24_19.npy', 'Span': [0, 921600]},\n",
       " {'Label': 'Inter16-3', 'File': 'chb24_20.npy', 'Span': [0, 719616]},\n",
       " {'Label': 'Pre16', 'File': 'chb24_21.npy', 'Span': [180224, 641024]},\n",
       " {'Label': 'Onset16', 'File': 'chb24_21.npy', 'Span': [717824, 735232]}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_all_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2074, 1, 25, 16, 26, 28),\n",
       "  datetime.datetime(2074, 1, 25, 17, 26, 28),\n",
       "  'chb24_01.npy'),\n",
       " (datetime.datetime(2074, 1, 25, 17, 26, 31),\n",
       "  datetime.datetime(2074, 1, 25, 18, 26, 31),\n",
       "  'chb24_02.npy'),\n",
       " (datetime.datetime(2074, 1, 25, 18, 26, 39),\n",
       "  datetime.datetime(2074, 1, 25, 19, 26, 39),\n",
       "  'chb24_03.npy'),\n",
       " (datetime.datetime(2074, 1, 25, 19, 26, 46),\n",
       "  datetime.datetime(2074, 1, 25, 20, 26, 46),\n",
       "  'chb24_04.npy'),\n",
       " (datetime.datetime(2074, 1, 25, 20, 26, 53),\n",
       "  datetime.datetime(2074, 1, 25, 21, 26, 53),\n",
       "  'chb24_05.npy'),\n",
       " (datetime.datetime(2074, 1, 25, 21, 27),\n",
       "  datetime.datetime(2074, 1, 25, 22, 27),\n",
       "  'chb24_06.npy'),\n",
       " (datetime.datetime(2074, 1, 25, 22, 27, 8),\n",
       "  datetime.datetime(2074, 1, 25, 23, 27, 8),\n",
       "  'chb24_07.npy'),\n",
       " (datetime.datetime(2074, 1, 25, 23, 27, 15),\n",
       "  datetime.datetime(2074, 1, 26, 0, 27, 15),\n",
       "  'chb24_08.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 0, 27, 22),\n",
       "  datetime.datetime(2074, 1, 26, 1, 27, 22),\n",
       "  'chb24_09.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 1, 27, 29),\n",
       "  datetime.datetime(2074, 1, 26, 2, 27, 29),\n",
       "  'chb24_10.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 2, 27, 36),\n",
       "  datetime.datetime(2074, 1, 26, 3, 27, 36),\n",
       "  'chb24_11.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 3, 27, 43),\n",
       "  datetime.datetime(2074, 1, 26, 4, 27, 43),\n",
       "  'chb24_12.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 4, 27, 50),\n",
       "  datetime.datetime(2074, 1, 26, 5, 27, 50),\n",
       "  'chb24_13.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 5, 27, 57),\n",
       "  datetime.datetime(2074, 1, 26, 6, 27, 57),\n",
       "  'chb24_14.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 6, 28, 5),\n",
       "  datetime.datetime(2074, 1, 26, 7, 28, 5),\n",
       "  'chb24_15.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 7, 28, 12),\n",
       "  datetime.datetime(2074, 1, 26, 8, 28, 12),\n",
       "  'chb24_16.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 8, 28, 19),\n",
       "  datetime.datetime(2074, 1, 26, 9, 28, 19),\n",
       "  'chb24_17.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 9, 28, 26),\n",
       "  datetime.datetime(2074, 1, 26, 10, 28, 26),\n",
       "  'chb24_18.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 10, 28, 35),\n",
       "  datetime.datetime(2074, 1, 26, 11, 28, 35),\n",
       "  'chb24_19.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 11, 28, 43),\n",
       "  datetime.datetime(2074, 1, 26, 12, 28, 43),\n",
       "  'chb24_20.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 12, 28, 50),\n",
       "  datetime.datetime(2074, 1, 26, 13, 28, 50),\n",
       "  'chb24_21.npy'),\n",
       " (datetime.datetime(2074, 1, 26, 13, 28, 57),\n",
       "  datetime.datetime(2074, 1, 26, 13, 46, 44),\n",
       "  'chb24_22.npy')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2074, 1, 25, 15, 34, 28),\n",
       "  datetime.datetime(2074, 1, 25, 17, 34, 28)),\n",
       " (datetime.datetime(2074, 1, 25, 16, 7, 19),\n",
       "  datetime.datetime(2074, 1, 25, 18, 7, 19)),\n",
       " (datetime.datetime(2074, 1, 25, 17, 30, 30),\n",
       "  datetime.datetime(2074, 1, 25, 19, 30, 30)),\n",
       " (datetime.datetime(2074, 1, 25, 18, 14, 42),\n",
       "  datetime.datetime(2074, 1, 25, 20, 14, 42)),\n",
       " (datetime.datetime(2074, 1, 25, 18, 44, 54),\n",
       "  datetime.datetime(2074, 1, 25, 20, 44, 54)),\n",
       " (datetime.datetime(2074, 1, 25, 18, 50, 17),\n",
       "  datetime.datetime(2074, 1, 25, 20, 50, 17)),\n",
       " (datetime.datetime(2074, 1, 25, 18, 55, 51),\n",
       "  datetime.datetime(2074, 1, 25, 20, 55, 51)),\n",
       " (datetime.datetime(2074, 1, 25, 20, 47, 29),\n",
       "  datetime.datetime(2074, 1, 25, 22, 47, 29)),\n",
       " (datetime.datetime(2074, 1, 25, 21, 27, 46),\n",
       "  datetime.datetime(2074, 1, 25, 23, 27, 46)),\n",
       " (datetime.datetime(2074, 1, 25, 23, 56, 27),\n",
       "  datetime.datetime(2074, 1, 26, 1, 56, 27)),\n",
       " (datetime.datetime(2074, 1, 26, 2, 26, 23),\n",
       "  datetime.datetime(2074, 1, 26, 4, 26, 23)),\n",
       " (datetime.datetime(2074, 1, 26, 4, 22, 38),\n",
       "  datetime.datetime(2074, 1, 26, 6, 22, 38)),\n",
       " (datetime.datetime(2074, 1, 26, 5, 0, 16),\n",
       "  datetime.datetime(2074, 1, 26, 7, 0, 16)),\n",
       " (datetime.datetime(2074, 1, 26, 6, 27, 17),\n",
       "  datetime.datetime(2074, 1, 26, 8, 27, 17)),\n",
       " (datetime.datetime(2074, 1, 26, 8, 26, 54),\n",
       "  datetime.datetime(2074, 1, 26, 10, 26, 54)),\n",
       " (datetime.datetime(2074, 1, 26, 12, 15, 34),\n",
       "  datetime.datetime(2074, 1, 26, 14, 15, 34))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noninter_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
